{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tasks DS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuDcJkrQInBd"
      },
      "source": [
        "# TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIIwNQtbIy9v",
        "outputId": "66f16055-23c9-4247-9673-4002bf6181eb"
      },
      "source": [
        "!pip install nltk"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQiDRD_dJN8y"
      },
      "source": [
        "import nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYAwCaWLJRHf"
      },
      "source": [
        "from nltk import tokenize\n",
        "from operator import itemgetter\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiFsqznwJeZ_"
      },
      "source": [
        "doc = 'The update sucks!! I use timer with an ambient sound with 30 min interval at night to sleep, but after 30 min, it does not stop the ambient sound. It keeps playing the sound until morning. uninstalling the app'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDrjzbIxJit9"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize \n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSVsKbI0JmBj",
        "outputId": "9cd1148b-f1ed-4215-ce0f-74c6774d58ed"
      },
      "source": [
        ">>> import nltk\n",
        ">>> nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lYhI95QJ9yF",
        "outputId": "823cf4fa-7caa-442b-9bc7-31ff8d438667"
      },
      "source": [
        "total_words = doc.split()\n",
        "total_word_length = len(total_words)\n",
        "print(total_word_length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "39\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPRFefFhKLCw",
        "outputId": "b7834a78-9ff3-4e31-92c4-cb867f45ea13"
      },
      "source": [
        "total_sentences = tokenize.sent_tokenize(doc)\n",
        "total_sent_len = len(total_sentences)\n",
        "print(total_sent_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHaCFXnmKPNh",
        "outputId": "51210c00-054a-43cc-d9eb-37d35d05d58a"
      },
      "source": [
        "\n",
        ">>> import nltk\n",
        ">>> nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8OkmQKMKVO4",
        "outputId": "fe6974f1-4367-4de3-9d74-22e04420dd9e"
      },
      "source": [
        "tf_score = {}\n",
        "for each_word in total_words:\n",
        "    each_word = each_word.replace('.','')\n",
        "    if each_word not in stop_words:\n",
        "        if each_word in tf_score:\n",
        "            tf_score[each_word] += 1\n",
        "        else:\n",
        "            tf_score[each_word] = 1\n",
        "\n",
        "# Dividing by total_word_length for each dictionary element\n",
        "tf_score.update((x, y/int(total_word_length)) for x, y in tf_score.items())\n",
        "print(tf_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'The': 0.02564102564102564, 'update': 0.02564102564102564, 'sucks!!': 0.02564102564102564, 'I': 0.02564102564102564, 'use': 0.02564102564102564, 'timer': 0.02564102564102564, 'ambient': 0.05128205128205128, 'sound': 0.07692307692307693, '30': 0.05128205128205128, 'min': 0.02564102564102564, 'interval': 0.02564102564102564, 'night': 0.02564102564102564, 'sleep,': 0.02564102564102564, 'min,': 0.02564102564102564, 'stop': 0.02564102564102564, 'It': 0.02564102564102564, 'keeps': 0.02564102564102564, 'playing': 0.02564102564102564, 'morning': 0.02564102564102564, 'uninstalling': 0.02564102564102564, 'app': 0.02564102564102564}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0DejgwdKdux"
      },
      "source": [
        "def check_sent(word, sentences): \n",
        "    final = [all([w in x for w in word]) for x in sentences] \n",
        "    sent_len = [sentences[i] for i in range(0, len(final)) if final[i]]\n",
        "    return int(len(sent_len))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3JvZhk9Kkrt",
        "outputId": "49e1f735-087e-45d4-c58c-b14634f11f85"
      },
      "source": [
        "idf_score = {}\n",
        "for each_word in total_words:\n",
        "    each_word = each_word.replace('.','')\n",
        "    if each_word not in stop_words:\n",
        "        if each_word in idf_score:\n",
        "            idf_score[each_word] = check_sent(each_word, total_sentences)\n",
        "        else:\n",
        "            idf_score[each_word] = 1\n",
        "\n",
        "# Performing a log and divide\n",
        "idf_score.update((x, math.log(int(total_sent_len)/y)) for x, y in idf_score.items())\n",
        "\n",
        "print(idf_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'The': 1.3862943611198906, 'update': 1.3862943611198906, 'sucks!!': 1.3862943611198906, 'I': 1.3862943611198906, 'use': 1.3862943611198906, 'timer': 1.3862943611198906, 'ambient': 1.3862943611198906, 'sound': 0.6931471805599453, '30': 1.3862943611198906, 'min': 1.3862943611198906, 'interval': 1.3862943611198906, 'night': 1.3862943611198906, 'sleep,': 1.3862943611198906, 'min,': 1.3862943611198906, 'stop': 1.3862943611198906, 'It': 1.3862943611198906, 'keeps': 1.3862943611198906, 'playing': 1.3862943611198906, 'morning': 1.3862943611198906, 'uninstalling': 1.3862943611198906, 'app': 1.3862943611198906}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91B6asocKs9q",
        "outputId": "8fc45363-2b03-46ca-b3ac-02285511c36d"
      },
      "source": [
        "tf_idf_score = {key: tf_score[key] * idf_score.get(key, 0) for key in tf_score.keys()}\n",
        "print(tf_idf_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'The': 0.035546009259484375, 'update': 0.035546009259484375, 'sucks!!': 0.035546009259484375, 'I': 0.035546009259484375, 'use': 0.035546009259484375, 'timer': 0.035546009259484375, 'ambient': 0.07109201851896875, 'sound': 0.053319013889226566, '30': 0.07109201851896875, 'min': 0.035546009259484375, 'interval': 0.035546009259484375, 'night': 0.035546009259484375, 'sleep,': 0.035546009259484375, 'min,': 0.035546009259484375, 'stop': 0.035546009259484375, 'It': 0.035546009259484375, 'keeps': 0.035546009259484375, 'playing': 0.035546009259484375, 'morning': 0.035546009259484375, 'uninstalling': 0.035546009259484375, 'app': 0.035546009259484375}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRXrHJAsKwNw"
      },
      "source": [
        "def get_top_n(dict_elem, n):\n",
        "    result = dict(sorted(dict_elem.items(), key = itemgetter(1), reverse = True)[:n]) \n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWgSeMGaKzN0",
        "outputId": "c99d0201-b699-43c3-a8af-78885829e656"
      },
      "source": [
        "print(get_top_n(tf_idf_score, 6))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'ambient': 0.07109201851896875, '30': 0.07109201851896875, 'sound': 0.053319013889226566, 'The': 0.035546009259484375, 'update': 0.035546009259484375, 'sucks!!': 0.035546009259484375}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSb9IZNCLYFt"
      },
      "source": [
        "# BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bi7AB9ihK1mv",
        "outputId": "36449209-2348-47d6-8a15-b4e3c3e18493"
      },
      "source": [
        "!pip install keybert\n",
        "!pip install keybert[flair]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keybert\n",
            "  Downloading https://files.pythonhosted.org/packages/5d/f4/65853bfc2ded495af3341a3f8938f17799d15a65be0150cb57774e1fb59f/keybert-0.2.0.tar.gz\n",
            "Collecting sentence-transformers>=0.3.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c4/87/49dc49e13ac107ce912c2f3f3fd92252c6d4221e88d1e6c16747044a11d8/sentence-transformers-1.1.0.tar.gz (78kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.7/dist-packages (from keybert) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from keybert) (1.19.5)\n",
            "Collecting transformers<5.0.0,>=3.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 30.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.41.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (1.8.1+cu101)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 42.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.2->keybert) (1.0.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 41.6MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 36.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert) (3.10.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers>=0.3.8->keybert) (3.7.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers>=0.3.8->keybert) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert) (3.4.1)\n",
            "Building wheels for collected packages: keybert, sentence-transformers\n",
            "  Building wheel for keybert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keybert: filename=keybert-0.2.0-cp37-none-any.whl size=10599 sha256=8324324873cb69cc76f8d04efc3f37bf955ed2839c1197fd1770240eb7553623\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/d7/16/04bab6677a4dfa9fd8ab2b350bac915d60f5378b83d6f5a372\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-1.1.0-cp37-none-any.whl size=119615 sha256=881aba82024f9046f523fbc746d762751daff1d2d20a708d75e4051586142f98\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/cb/21/1066bff3027215c760ca14a198f698bca8fccb92e33e2327eb\n",
            "Successfully built keybert sentence-transformers\n",
            "Installing collected packages: tokenizers, sacremoses, transformers, sentencepiece, sentence-transformers, keybert\n",
            "Successfully installed keybert-0.2.0 sacremoses-0.0.45 sentence-transformers-1.1.0 sentencepiece-0.1.95 tokenizers-0.10.2 transformers-4.5.1\n",
            "Requirement already satisfied: keybert[flair] in /usr/local/lib/python3.7/dist-packages (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from keybert[flair]) (1.19.5)\n",
            "Requirement already satisfied: sentence-transformers>=0.3.8 in /usr/local/lib/python3.7/dist-packages (from keybert[flair]) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.7/dist-packages (from keybert[flair]) (0.22.2.post1)\n",
            "Collecting flair==0.7; extra == \"flair\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/a0/a1b41fa2fcb23ff71ba9148af75211dcccc35b256dea821b36e1ee871848/flair-0.7-py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 17.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert[flair]) (1.8.1+cu101)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert[flair]) (0.1.95)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert[flair]) (4.41.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert[flair]) (4.5.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert[flair]) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert[flair]) (3.2.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.2->keybert[flair]) (1.0.1)\n",
            "Collecting langdetect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/a3/8407c1e62d5980188b4acc45ef3d94b933d14a2ebc9ef3505f22cf772570/langdetect-1.0.8.tar.gz (981kB)\n",
            "\u001b[K     |████████████████████████████████| 983kB 17.7MB/s \n",
            "\u001b[?25hCollecting deprecated>=1.2.4\n",
            "  Downloading https://files.pythonhosted.org/packages/fb/73/994edfcba74443146c84b91921fcc269374354118d4f452fb0c54c1cbb12/Deprecated-1.2.12-py2.py3-none-any.whl\n",
            "Collecting ftfy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/b5/5da463f9c7823e0e575e9908d004e2af4b36efa8d02d3d6dad57094fcb11/ftfy-6.0.1.tar.gz (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.0MB/s \n",
            "\u001b[?25hCollecting bpemb>=0.3.2\n",
            "  Downloading https://files.pythonhosted.org/packages/f2/6f/9191b85109772636a8f8accb122900c34db26c091d2793218aa94954524c/bpemb-0.3.3-py3-none-any.whl\n",
            "Collecting mpld3==0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n",
            "\u001b[K     |████████████████████████████████| 798kB 39.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: gensim<=3.8.3,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from flair==0.7; extra == \"flair\"->keybert[flair]) (3.6.0)\n",
            "Collecting konoha<5.0.0,>=4.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/02/be/4dd30d56a0a19619deb9bf41ba8202709fa83b1b301b876572cd6dc38117/konoha-4.6.4-py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from flair==0.7; extra == \"flair\"->keybert[flair]) (2.8.1)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (from flair==0.7; extra == \"flair\"->keybert[flair]) (3.6.4)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from flair==0.7; extra == \"flair\"->keybert[flair]) (0.8.9)\n",
            "Collecting sqlitedict>=1.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/2d/b1d99e9ad157dd7de9cd0d36a8a5876b13b55e4b75f7498bc96035fb4e96/sqlitedict-1.7.0.tar.gz\n",
            "Collecting janome\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/63/98858cbead27df7536c7e300c169da0999e9704d02220dc6700b804eeff0/Janome-0.4.1-py2.py3-none-any.whl (19.7MB)\n",
            "\u001b[K     |████████████████████████████████| 19.7MB 1.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from flair==0.7; extra == \"flair\"->keybert[flair]) (2019.12.20)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from flair==0.7; extra == \"flair\"->keybert[flair]) (4.2.6)\n",
            "Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from flair==0.7; extra == \"flair\"->keybert[flair]) (0.1.2)\n",
            "Collecting segtok>=1.5.7\n",
            "  Downloading https://files.pythonhosted.org/packages/41/08/582dab5f4b1d5ca23bc6927b4bb977c8ff7f3a87a3b98844ef833e2f5623/segtok-1.5.10.tar.gz\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.7/dist-packages (from flair==0.7; extra == \"flair\"->keybert[flair]) (3.2.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers>=0.3.8->keybert[flair]) (3.7.4.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert[flair]) (2.23.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert[flair]) (0.10.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert[flair]) (3.10.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert[flair]) (0.0.45)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert[flair]) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert[flair]) (20.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers>=0.3.8->keybert[flair]) (1.15.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.4->flair==0.7; extra == \"flair\"->keybert[flair]) (1.12.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->flair==0.7; extra == \"flair\"->keybert[flair]) (0.2.5)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim<=3.8.3,>=3.4.0->flair==0.7; extra == \"flair\"->keybert[flair]) (5.0.0)\n",
            "Collecting overrides<4.0.0,>=3.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/b1/10f69c00947518e6676bbd43e739733048de64b8dd998e9c2d5a71f44c5d/overrides-3.1.0.tar.gz\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair==0.7; extra == \"flair\"->keybert[flair]) (2.5.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair==0.7; extra == \"flair\"->keybert[flair]) (0.16.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair==0.7; extra == \"flair\"->keybert[flair]) (3.11.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair==0.7; extra == \"flair\"->keybert[flair]) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair==0.7; extra == \"flair\"->keybert[flair]) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair==0.7; extra == \"flair\"->keybert[flair]) (1.3.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert[flair]) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert[flair]) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert[flair]) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert[flair]) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert[flair]) (3.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert[flair]) (7.1.2)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->hyperopt>=0.1.1->flair==0.7; extra == \"flair\"->keybert[flair]) (4.4.2)\n",
            "Building wheels for collected packages: langdetect, ftfy, mpld3, sqlitedict, segtok, overrides\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.8-cp37-none-any.whl size=993193 sha256=49b3cb1a9730997ea3347b1f050329df5bd002658c0bb0fa2b7a41f20b19032c\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/b3/aa/6d99de9f3841d7d3d40a60ea06e6d669e8e5012e6c8b947a57\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-6.0.1-cp37-none-any.whl size=41573 sha256=f6d11bfe65690b6373893f5e94ca26983ba1d9ec818bf9c4621aec72d270610e\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/73/c7/9056e14b04919e5c262fe80b54133b1a88d73683d05d7ac65c\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-cp37-none-any.whl size=116679 sha256=a1239759070ac5d4b01065016500b839b5a63c4d8cde983dde4171d2c920c7e2\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-1.7.0-cp37-none-any.whl size=14376 sha256=a7d65a073aafe43dca34c990c443ddff551a1228da8218f0ec3894d994405e2f\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/c6/4f/2c64a43f041415eb8b8740bd80e15e92f0d46c5e464d8e4b9b\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segtok: filename=segtok-1.5.10-cp37-none-any.whl size=25019 sha256=cbb4fa746ea942dd781ae3e0a12b0a40fd76fdf35c126534f5a879a87fd52a4f\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/39/f6/9ca1c5cabde964d728023b5751c3a206a5c8cc40252321fb6b\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-cp37-none-any.whl size=10174 sha256=28ac1d492ee727c3ab65722c91843c20722d48d550eb295b55ec86ed05089538\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/24/13/6ef8600e6f147c95e595f1289a86a3cc82ed65df57582c65a9\n",
            "Successfully built langdetect ftfy mpld3 sqlitedict segtok overrides\n",
            "\u001b[31mERROR: konoha 4.6.4 has requirement requests<3.0.0,>=2.25.1, but you'll have requests 2.23.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: flair 0.7 has requirement sentencepiece<=0.1.91, but you'll have sentencepiece 0.1.95 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: flair 0.7 has requirement transformers<=3.5.1,>=3.5.0, but you'll have transformers 4.5.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: langdetect, deprecated, ftfy, bpemb, mpld3, overrides, konoha, sqlitedict, janome, segtok, flair\n",
            "Successfully installed bpemb-0.3.3 deprecated-1.2.12 flair-0.7 ftfy-6.0.1 janome-0.4.1 konoha-4.6.4 langdetect-1.0.8 mpld3-0.3 overrides-3.1.0 segtok-1.5.10 sqlitedict-1.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQzry3TcLeg8"
      },
      "source": [
        "from keybert import KeyBERT\n",
        "\n",
        "doc = \"\"\" The update sucks!! I use timer with an ambient sound with 30 min interval at night to sleep, but after 30 min, it does not stop the ambient sound. It keeps playing the sound until morning. uninstalling the app\"\"\"\n",
        "model = KeyBERT('distilbert-base-nli-mean-tokens')\n",
        "keywords = model.extract_keywords(doc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "If3Tg5sGLxVD",
        "outputId": "ab884b3f-35f4-4c38-e490-d7b5a109a8eb"
      },
      "source": [
        " model.extract_keywords(doc, keyphrase_ngram_range=(1,2), stop_words=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('morning uninstalling', 0.2273),\n",
              " ('until morning', 0.2143),\n",
              " ('at night', 0.2071),\n",
              " ('30 min', 0.1981),\n",
              " ('to sleep', 0.1854)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxvZhFobMEi9"
      },
      "source": [
        "# YAKE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FI2FSd9gMlnI",
        "outputId": "4dc878e5-7f2b-458a-b184-35a0f272f5b9"
      },
      "source": [
        "!pip install yake"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting yake\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/7f/c4de4fb40639ec674f944d82e5b0be5a5a9162fc8e83e379ab10b83ee1f9/yake-0.4.8-py2.py3-none-any.whl (60kB)\n",
            "\r\u001b[K     |█████▌                          | 10kB 15.0MB/s eta 0:00:01\r\u001b[K     |███████████                     | 20kB 21.3MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 30kB 25.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 40kB 22.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 51kB 22.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 5.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from yake) (2.5.1)\n",
            "Requirement already satisfied: click>=6.0 in /usr/local/lib/python3.7/dist-packages (from yake) (7.1.2)\n",
            "Collecting jellyfish\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/a6/4d039bc827a102f62ce7a7910713e38fdfd7c7a40aa39c72fb14938a1473/jellyfish-0.8.2-cp37-cp37m-manylinux2014_x86_64.whl (90kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 6.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from yake) (0.8.9)\n",
            "Requirement already satisfied: segtok in /usr/local/lib/python3.7/dist-packages (from yake) (1.5.10)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from yake) (1.19.5)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->yake) (4.4.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from segtok->yake) (2019.12.20)\n",
            "Installing collected packages: jellyfish, yake\n",
            "Successfully installed jellyfish-0.8.2 yake-0.4.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8IGKShtMne6"
      },
      "source": [
        "import yake\n",
        "kw_extractor = yake.KeywordExtractor()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyYjT9CNMqvm"
      },
      "source": [
        "text = \"The update sucks!! I use timer with an ambient sound with 30 min interval at night to sleep, but after 30 min, it does not stop the ambient sound. It keeps playing the sound until morning. uninstalling the app\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TkeFqrmMttx",
        "outputId": "3d8b9899-f2b6-485b-9559-74f02822fe92"
      },
      "source": [
        "language = \"en\"\n",
        "max_ngram_size = 1\n",
        "deduplication_threshold = 0.2\n",
        "numOfKeywords = 5\n",
        "custom_kw_extractor = yake.KeywordExtractor(lan=language, n=max_ngram_size, dedupLim=deduplication_threshold, top=numOfKeywords, features=None)\n",
        "keywords = custom_kw_extractor.extract_keywords(text)\n",
        "for kw in keywords:\n",
        "    print(kw)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('sucks', 0.1579493124205724)\n",
            "('sound', 0.16531380572351637)\n",
            "('min', 0.1790978185181025)\n",
            "('update', 0.2126671337626293)\n",
            "('sleep', 0.3944777858006638)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15HGf3fXM3ad"
      },
      "source": [
        "# RAKE spaCy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AnF6jZ7MwsB"
      },
      "source": [
        "import spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOYkJky9NM9r",
        "outputId": "9dd4be0e-d5be-4034-8911-e118f042e390"
      },
      "source": [
        "!python -m spacy download en_core_web_lg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_lg==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz#egg=en_core_web_lg==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_lg==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (56.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.4.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vue6iLGKO9WM",
        "outputId": "224420c0-c37f-40f1-e260-c638fc16e76a"
      },
      "source": [
        "!pip install rake-spacy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting rake-spacy\n",
            "  Downloading https://files.pythonhosted.org/packages/d7/c0/a839a3d487e9eb584d2fd9da98a9052a90fcdaea3ac535988a83947f08e5/rake_spacy-0.3.1-py3-none-any.whl\n",
            "Requirement already satisfied: spacy<4.0,>=2.2 in /usr/local/lib/python3.7/dist-packages (from rake-spacy) (2.2.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=2.2->rake-spacy) (2.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=2.2->rake-spacy) (56.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=2.2->rake-spacy) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=2.2->rake-spacy) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=2.2->rake-spacy) (1.19.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=2.2->rake-spacy) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=2.2->rake-spacy) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=2.2->rake-spacy) (3.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=2.2->rake-spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=2.2->rake-spacy) (1.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=2.2->rake-spacy) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=2.2->rake-spacy) (0.8.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0,>=2.2->rake-spacy) (7.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<4.0,>=2.2->rake-spacy) (3.10.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0,>=2.2->rake-spacy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0,>=2.2->rake-spacy) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0,>=2.2->rake-spacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0,>=2.2->rake-spacy) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<4.0,>=2.2->rake-spacy) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<4.0,>=2.2->rake-spacy) (3.7.4.3)\n",
            "Installing collected packages: rake-spacy\n",
            "Successfully installed rake-spacy-0.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gsg0E_OyNPV_",
        "outputId": "39ac0444-f2b3-4c2d-88d1-fd60ef303c4a"
      },
      "source": [
        "from rake_spacy import Rake\n",
        "import spacy\n",
        "\n",
        "r = Rake()\n",
        "text = \"The update sucks!! I use timer with an ambient sound with 30 min interval at night to sleep, but after 30 min, it does not stop the ambient sound. It keeps playing the sound until morning. uninstalling the app\"\n",
        "\n",
        "# Rake is now using the provided nlp object to prase the document\n",
        "ranklist = r.apply(text)\n",
        "print(ranklist)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(5.0, 30 min interval), (5.0, ambient sound), (5.0, ambient sound), (4.0, 30 min), (3.0, sound), (2.0, keeps playing), (2.0, update sucks), (2.0, use timer), (1.0, app), (1.0, morning), (1.0, night), (1.0, sleep), (1.0, stop), (1.0, uninstalling)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbpLFOz_QLbF"
      },
      "source": [
        "# RAKE - NLTK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGBTRyj7QY_D",
        "outputId": "81f30144-d5ae-4bbd-cf5c-10e29ef4ec62"
      },
      "source": [
        "!pip install rake_nltk"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting rake_nltk\n",
            "  Downloading https://files.pythonhosted.org/packages/8e/c4/b4ff57e541ac5624ad4b20b89c2bafd4e98f29fd83139f3a81858bdb3815/rake_nltk-1.0.4.tar.gz\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from rake_nltk) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->rake_nltk) (1.15.0)\n",
            "Building wheels for collected packages: rake-nltk\n",
            "  Building wheel for rake-nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rake-nltk: filename=rake_nltk-1.0.4-py2.py3-none-any.whl size=7819 sha256=4211c061cf78b62ed83b5d12732d19470b6ed71019d3b629e289f3ef5864a7fb\n",
            "  Stored in directory: /root/.cache/pip/wheels/ef/92/fc/271b3709e71a96ffe934b27818946b795ac6b9b8ff8682483f\n",
            "Successfully built rake-nltk\n",
            "Installing collected packages: rake-nltk\n",
            "Successfully installed rake-nltk-1.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKPNCcOTQQDp",
        "outputId": "e999818d-4d10-43f5-d76f-9e5024abef63"
      },
      "source": [
        "from rake_nltk import Rake\n",
        "rake = Rake()\n",
        "\n",
        "text = \"The update sucks!! I use timer with an ambient sound with 30 min interval at night to sleep, but after 30 min, it does not stop the ambient sound. It keeps playing the sound until morning. uninstalling the app\"\n",
        "rake.extract_keywords_from_text(text)\n",
        "\n",
        "print(rake.get_ranked_phrases_with_scores())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(9.0, 'update sucks !!'), (8.0, '30 min interval'), (5.0, '30 min'), (4.0, 'use timer'), (4.0, 'keeps playing'), (3.5, 'ambient sound'), (1.5, 'sound'), (1.0, 'uninstalling'), (1.0, 'stop'), (1.0, 'sleep'), (1.0, 'night'), (1.0, 'morning'), (1.0, 'app')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvMqPl4MgIlB"
      },
      "source": [
        "# PKE YAKE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYTWcwS4gWVo",
        "outputId": "e42402a1-a79c-4c5c-edb6-1992873d3edf"
      },
      "source": [
        "!pip install git+https://github.com/boudinfl/pke.git\n",
        "!python -m nltk.downloader stopwords\n",
        "!python -m spacy download en"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/boudinfl/pke.git\n",
            "  Cloning https://github.com/boudinfl/pke.git to /tmp/pip-req-build-9450m2a5\n",
            "  Running command git clone -q https://github.com/boudinfl/pke.git /tmp/pip-req-build-9450m2a5\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from pke==1.8.1) (3.2.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from pke==1.8.1) (2.5.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pke==1.8.1) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pke==1.8.1) (1.4.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (from pke==1.8.1) (2.2.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pke==1.8.1) (1.15.0)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from pke==1.8.1) (0.0)\n",
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/25/723487ca2a52ebcee88a34d7d1f5a4b80b793f179ee0f62d5371938dfa01/Unidecode-1.2.0-py2.py3-none-any.whl (241kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 7.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pke==1.8.1) (0.16.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pke==1.8.1) (1.0.1)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->pke==1.8.1) (4.4.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (0.8.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (56.0.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (4.41.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (1.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (2.23.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (2.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (3.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->pke==1.8.1) (0.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->pke==1.8.1) (0.22.2.post1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->pke==1.8.1) (3.10.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pke==1.8.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pke==1.8.1) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pke==1.8.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pke==1.8.1) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->pke==1.8.1) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->pke==1.8.1) (3.7.4.3)\n",
            "Building wheels for collected packages: pke\n",
            "  Building wheel for pke (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pke: filename=pke-1.8.1-cp37-none-any.whl size=8763776 sha256=6156f39f0a7d6733e541a3748944d32cd0a2dd70238a113d7956fdb0f71d6538\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-bhmsuc85/wheels/8d/24/54/6582e854e9e32dd6c632af6762b3a5d2f6b181c2992e165462\n",
            "Successfully built pke\n",
            "Installing collected packages: unidecode, pke\n",
            "Successfully installed pke-1.8.1 unidecode-1.2.0\n",
            "/usr/lib/python3.7/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (56.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpY2626qQWZM"
      },
      "source": [
        "from pke.unsupervised import YAKE\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPO025UMhFH5"
      },
      "source": [
        "document = \"The update sucks!! I use timer with an ambient sound with 30 min interval at night to sleep, but after 30 min, it does not stop the sound. It keeps playing the sound until morning. uninstalling the app\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8Ql04mlgP3j",
        "outputId": "1ebff664-4596-49ec-b19d-5435d2d2f055"
      },
      "source": [
        "#  YAKE keyword extractor\n",
        "extractor = YAKE()\n",
        "\n",
        "\n",
        "extractor.load_document(input=document,\n",
        "                        language='en',\n",
        "                        normalization=None)\n",
        "\n",
        "\n",
        "# 1-gram and 2-gram keywords\n",
        "stoplist = stopwords.words('english')\n",
        "extractor.candidate_selection(n=1, stoplist=stoplist)\n",
        "\n",
        "# scores\n",
        "extractor.candidate_weighting(window=2,\n",
        "                              stoplist=stoplist,\n",
        "                              use_stems=False)\n",
        "\n",
        "# 5 highest ranked keywords and remove redundant keywords with similarity above 80%\n",
        "key_phrases = extractor.get_n_best(n=5, threshold=0.8)\n",
        "print(key_phrases)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('sucks', 0.1533130244582476), ('sound', 0.17104051799171605), ('update', 0.20681920122715958), ('min', 0.22771423868224977), ('sleep', 0.38608197349254303)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEJKV1ExhcMn"
      },
      "source": [
        "# LDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3sd8YyLg6c4"
      },
      "source": [
        "import pandas as pd\n",
        "import gensim # for Topic modelling\n",
        "from gensim.models.ldamulticore import LdaMulticore\n",
        "from gensim import corpora, models\n",
        "\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "from itertools import chain"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnBBJsb0hlno"
      },
      "source": [
        "text = \"The update sucks!! I use timer with an ambient sound with 30 min interval at night to sleep, but after 30 min, it does not stop the ambient sound. It keeps playing the sound until morning. uninstalling the app\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwZnTyChhuPO"
      },
      "source": [
        "stop = set(stopwords.words('english'))\n",
        "exclude = set(string.punctuation)\n",
        "lemma = WordNetLemmatizer()\n",
        "\n",
        "def clean(text):\n",
        "    stop_free = ' '.join([word for word in text.lower().split() if word not in stop])\n",
        "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
        "    normalized = ' '.join([lemma.lemmatize(word) for word in punc_free.split()])\n",
        "    return normalized.split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AVoX6WGiIoQ"
      },
      "source": [
        "lda = gensim.models.ldamodel.LdaModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXT0berFhxcP",
        "outputId": "0284c26c-ed65-47c1-c295-92e09ee4ab1c"
      },
      "source": [
        "dictionary = corpora.Dictionary([text.split()])\n",
        "doc_term_matrix = [dictionary.doc2bow(doc) for doc in [text.split()]]\n",
        "num_topics=2\n",
        "%time ldamodel = lda(id2word=dictionary,passes=100,minimum_probability=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2.66 ms, sys: 0 ns, total: 2.66 ms\n",
            "Wall time: 3.17 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9N1c2ouSiBfk",
        "outputId": "0f674a7d-e7e0-48d8-fa35-97770e35de47"
      },
      "source": [
        "ldamodel.print_topics(num_topics)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(24,\n",
              "  '0.035*\"min\" + 0.034*\"update\" + 0.034*\"sucks!!\" + 0.033*\"an\" + 0.033*\"app\" + 0.033*\"with\" + 0.032*\"stop\" + 0.032*\"I\" + 0.032*\"the\" + 0.032*\"at\"'),\n",
              " (0,\n",
              "  '0.035*\"after\" + 0.034*\"ambient\" + 0.034*\"night\" + 0.033*\"sound\" + 0.033*\"min,\" + 0.033*\"to\" + 0.033*\"does\" + 0.033*\"with\" + 0.032*\"but\" + 0.032*\"sound.\"')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrVIMwGLil-S"
      },
      "source": [
        "# Gensim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRJtHLVJiNQH"
      },
      "source": [
        "from gensim.summarization import keywords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8libc2hiqIO"
      },
      "source": [
        "text = \"The update sucks!! I use timer with an ambient sound with 30 min interval at night to sleep, but after 30 min, it does not stop the ambient sound. It keeps playing the sound until morning. uninstalling the app\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzMSjRB7ivB1",
        "outputId": "be846635-324f-4087-d6e6-9599ba402131"
      },
      "source": [
        "print(keywords(text, words=5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "update\n",
            "sucks\n",
            "ambient sound\n",
            "keeps\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drS3ar9rkZg_"
      },
      "source": [
        "# TextRank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbEZVslwixjI",
        "outputId": "bb887f5b-19a3-434d-d928-12a3eeb07445"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "content = '''\n",
        "The update sucks!! I use timer with an ambient sound with 30 min interval at night to sleep, but after 30 min, it does not stop the ambient sound. It keeps playing the sound until morning. uninstalling the app\n",
        "'''\n",
        "doc = nlp(content)\n",
        "for sents in doc.sents:\n",
        "    print(sents.text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "The update sucks!!\n",
            "I use timer with an ambient sound with 30 min interval at night to sleep, but after 30 min, it does not stop the ambient sound.\n",
            "It keeps playing the sound until morning.\n",
            "uninstalling the app\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rv-Yr9cQkdpB",
        "outputId": "39d6c187-fa3a-454e-89f3-f946ba0cbff7"
      },
      "source": [
        "candidate_pos = ['NOUN', 'PROPN', 'VERB']\n",
        "sentences = []\n",
        "\n",
        "for sent in doc.sents:\n",
        "    selected_words = []\n",
        "    for token in sent:\n",
        "        if token.pos_ in candidate_pos and token.is_stop is False:\n",
        "            selected_words.append(token)\n",
        "    sentences.append(selected_words)\n",
        "\n",
        "print(sentences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[update, sucks], [use, timer, sound, min, interval, night, sleep, min, stop, sound], [keeps, playing, sound, morning], [uninstalling, app]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D15Tia-4lX5T"
      },
      "source": [
        "from collections import OrderedDict\n",
        "import numpy as np\n",
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "class TextRank4Keyword():\n",
        "    \"\"\"Extract keywords from text\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.d = 0.85 # damping coefficient, usually is .85\n",
        "        self.min_diff = 1e-5 # convergence threshold\n",
        "        self.steps = 10 # iteration steps\n",
        "        self.node_weight = None # save keywords and its weight\n",
        "\n",
        "    \n",
        "    def set_stopwords(self, stopwords):  \n",
        "        \"\"\"Set stop words\"\"\"\n",
        "        for word in STOP_WORDS.union(set(stopwords)):\n",
        "            lexeme = nlp.vocab[word]\n",
        "            lexeme.is_stop = True\n",
        "    \n",
        "    def sentence_segment(self, doc, candidate_pos, lower):\n",
        "        \"\"\"Store those words only in cadidate_pos\"\"\"\n",
        "        sentences = []\n",
        "        for sent in doc.sents:\n",
        "            selected_words = []\n",
        "            for token in sent:\n",
        "                # Store words only with cadidate POS tag\n",
        "                if token.pos_ in candidate_pos and token.is_stop is False:\n",
        "                    if lower is True:\n",
        "                        selected_words.append(token.text.lower())\n",
        "                    else:\n",
        "                        selected_words.append(token.text)\n",
        "            sentences.append(selected_words)\n",
        "        return sentences\n",
        "        \n",
        "    def get_vocab(self, sentences):\n",
        "        \"\"\"Get all tokens\"\"\"\n",
        "        vocab = OrderedDict()\n",
        "        i = 0\n",
        "        for sentence in sentences:\n",
        "            for word in sentence:\n",
        "                if word not in vocab:\n",
        "                    vocab[word] = i\n",
        "                    i += 1\n",
        "        return vocab\n",
        "    \n",
        "    def get_token_pairs(self, window_size, sentences):\n",
        "        \"\"\"Build token_pairs from windows in sentences\"\"\"\n",
        "        token_pairs = list()\n",
        "        for sentence in sentences:\n",
        "            for i, word in enumerate(sentence):\n",
        "                for j in range(i+1, i+window_size):\n",
        "                    if j >= len(sentence):\n",
        "                        break\n",
        "                    pair = (word, sentence[j])\n",
        "                    if pair not in token_pairs:\n",
        "                        token_pairs.append(pair)\n",
        "        return token_pairs\n",
        "        \n",
        "    def symmetrize(self, a):\n",
        "        return a + a.T - np.diag(a.diagonal())\n",
        "    \n",
        "    def get_matrix(self, vocab, token_pairs):\n",
        "        \"\"\"Get normalized matrix\"\"\"\n",
        "        # Build matrix\n",
        "        vocab_size = len(vocab)\n",
        "        g = np.zeros((vocab_size, vocab_size), dtype='float')\n",
        "        for word1, word2 in token_pairs:\n",
        "            i, j = vocab[word1], vocab[word2]\n",
        "            g[i][j] = 1\n",
        "            \n",
        "        # Get Symmeric matrix\n",
        "        g = self.symmetrize(g)\n",
        "        \n",
        "        # Normalize matrix by column\n",
        "        norm = np.sum(g, axis=0)\n",
        "        g_norm = np.divide(g, norm, where=norm!=0) # this is ignore the 0 element in norm\n",
        "        \n",
        "        return g_norm\n",
        "\n",
        "    \n",
        "    def get_keywords(self, number=10):\n",
        "        \"\"\"Print top number keywords\"\"\"\n",
        "        node_weight = OrderedDict(sorted(self.node_weight.items(), key=lambda t: t[1], reverse=True))\n",
        "        for i, (key, value) in enumerate(node_weight.items()):\n",
        "            print(key + ' - ' + str(value))\n",
        "            if i > number:\n",
        "                break\n",
        "        \n",
        "        \n",
        "    def analyze(self, text, \n",
        "                candidate_pos=['NOUN', 'PROPN'], \n",
        "                window_size=4, lower=False, stopwords=list()):\n",
        "        \"\"\"Main function to analyze text\"\"\"\n",
        "        \n",
        "        # Set stop words\n",
        "        self.set_stopwords(stopwords)\n",
        "        \n",
        "        # Pare text by spaCy\n",
        "        doc = nlp(text)\n",
        "        \n",
        "        # Filter sentences\n",
        "        sentences = self.sentence_segment(doc, candidate_pos, lower) # list of list of words\n",
        "        \n",
        "        # Build vocabulary\n",
        "        vocab = self.get_vocab(sentences)\n",
        "        \n",
        "        # Get token_pairs from windows\n",
        "        token_pairs = self.get_token_pairs(window_size, sentences)\n",
        "        \n",
        "        # Get normalized matrix\n",
        "        g = self.get_matrix(vocab, token_pairs)\n",
        "        \n",
        "        # Initionlization for weight(pagerank value)\n",
        "        pr = np.array([1] * len(vocab))\n",
        "        \n",
        "        # Iteration\n",
        "        previous_pr = 0\n",
        "        for epoch in range(self.steps):\n",
        "            pr = (1-self.d) + self.d * np.dot(g, pr)\n",
        "            if abs(previous_pr - sum(pr))  < self.min_diff:\n",
        "                break\n",
        "            else:\n",
        "                previous_pr = sum(pr)\n",
        "\n",
        "        # Get weight for each node\n",
        "        node_weight = dict()\n",
        "        for word, index in vocab.items():\n",
        "            node_weight[word] = pr[index]\n",
        "        \n",
        "        self.node_weight = node_weight"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKZTe0BplmG7",
        "outputId": "fdaed75c-b77c-4e3f-a097-321bd76cda0f"
      },
      "source": [
        "text = '''\n",
        "The update sucks!! I use timer with an ambient sound with 30 min interval at night to sleep, but after 30 min, it does not stop the ambient sound. It keeps playing the sound until morning. uninstalling the app\n",
        "'''\n",
        "\n",
        "tr4w = TextRank4Keyword()\n",
        "tr4w.analyze(text, candidate_pos = ['NOUN', 'PROPN'], window_size=5, lower=False)\n",
        "tr4w.get_keywords(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "min - 1.369587673611111\n",
            "sound - 1.2967621527777777\n",
            "interval - 1.107282986111111\n",
            "night - 1.107282986111111\n",
            "timer - 0.7574696180555555\n",
            "morning - 0.36161458333333335\n",
            "update - 0.15000000000000002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYFIuG8tT8E2"
      },
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIzJKwcYUCPU"
      },
      "source": [
        "In this project, I have seen and worked on different approaches to extract keywords from a given text. All of them don’t require any pre training on a dataset. This list of algorithm and method is far from being complete, we can also test other approached but for now this will do. Here, I have both simple approaches like TF-IDF and advanced models like BERT. Unfortunately, there isn’t a model that performs well on every document. It depends on the type of document, the context, and the corpus used for the model pre-training (if required). A more complete preprocessing with a combination of different keyword extraction approaches should definitely improve the performance. But one highlight of all these approaches is the fast execution and implementation of their codes.  The RAKE and YAKE with their associate modules works exceptionally well and stand out with the use case example with their faster execution and easy implementation. Gensim and TextRank are also good for keywork extraction.                           "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uWEr40tUD5n"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}